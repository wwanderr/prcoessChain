# 实体节点过滤详解

## 概述

`filterEntityNodesInGraph` 是实体节点过滤的核心函数，负责对进程链图中的实体节点进行去重、优先级排序和数量控制。

**核心理念：** 每个进程节点可能产生大量实体节点（文件、域名、网络连接、注册表），为避免图过于庞大，需要对实体节点进行精细化过滤，保留最关键的信息。

**所在位置：** `EntityFilterUtil.java`

---

## 工作流程

### 总体流程

```
filterEntityNodesInGraph
    ├─ 步骤1：收集实体节点，按 processGuid 分组
    ├─ 步骤2：对每个 processGuid 的实体节点进行过滤
    │   ├─ 2.1 按实体类型分组 (file/domain/network/registry)
    │   ├─ 2.2 去重（根据唯一键）
    │   ├─ 2.3 应用过滤规则（优先级 + 数量限制）
    │   └─ 2.4 标记要移除的节点
    └─ 步骤3：批量移除标记的节点
```

---

## 具体示例：一个进程下挂了3个文件实体

### 场景设定

假设进程链图中有如下结构：

```
进程节点: PROC_12345 (malware.exe)
    ├── 实体节点1: PROC_12345_FILE_hash1 
    │   └─ 文件: malware.exe, opType=create, time=10:00:00, md5=abc123
    │
    ├── 实体节点2: PROC_12345_FILE_hash2
    │   └─ 文件: config.txt, opType=create, time=10:01:00, md5=def456
    │
    └── 实体节点3: PROC_12345_FILE_hash3
        └─ 文件: data.log, opType=modify, time=10:02:00, md5=ghi789
```

---

## 步骤1：收集实体节点，按 processGuid 分组

### 函数：`groupEntityNodesByProcess(graph)`

```java
Map<String, List<GraphNode>> result = new HashMap<>();

for (GraphNode node : graph.getAllNodes()) {
    // 1. 判断是否是实体节点
    if (!isEntityNode(node)) {
        continue;  // 跳过进程节点、虚拟节点等
    }
    
    // 2. 找到这个实体节点的父进程 processGuid
    String processGuid = findProcessGuidForEntityNode(graph, node);
    
    // 3. 按 processGuid 分组
    if (processGuid != null) {
        result.computeIfAbsent(processGuid, k -> new ArrayList<>())
              .add(node);
    }
}
```

### 如何判断是否是实体节点？

**函数：`isEntityNode(node)`**

```java
String type = node.getNodeType().toLowerCase();
return type.contains("file") || 
       type.contains("domain") || 
       type.contains("network") || 
       type.contains("registry") ||
       type.equals("file_entity") ||
       type.equals("domain_entity") ||
       type.equals("network_entity") ||
       type.equals("registry_entity");
```

**判断依据：** 节点的 `nodeType` 包含实体类型关键字

---

### 如何找到实体节点的父进程？

**函数：`findProcessGuidForEntityNode(graph, entityNode)`**

提供两种方式：

#### 方式1：从图的边关系获取（主要方式）

```java
// 获取实体节点的父节点
List<String> parents = graph.getParents(entityNode.getNodeId());

if (!parents.isEmpty()) {
    // 第一个父节点就是进程节点
    return parents.get(0);  // 返回 "PROC_12345"
}
```

**原理：** 
- 在 `EntityExtractor.extractEntitiesFromGraph` 中创建实体节点时，会建立边关系：
  ```java
  graph.addEdge(processGuid, entityNodeId, "连接");
  ```
- 因此，实体节点的父节点就是它所属的进程节点

#### 方式2：从 nodeId 推断（兜底方案）

```java
// 实体节点 ID 格式：processGuid_TYPE_hash
// 例如: "PROC_12345_FILE_hash1"
String nodeId = entityNode.getNodeId();
if (nodeId != null && nodeId.contains("_")) {
    return nodeId.substring(0, nodeId.indexOf("_"));  // 提取 "PROC_12345"
}
```

**使用场景：** 当图的边关系不完整时的兜底方案

---

### 输出结果

```java
entityNodesByProcess = {
    "PROC_12345" -> [实体节点1, 实体节点2, 实体节点3]
}
```

**关键点：** 
- 按 `processGuid` 分组，确保每个进程的实体节点**独立过滤**
- 不同进程的实体节点互不影响

---

## 步骤2：对每个 processGuid 的实体节点进行过滤

```java
for (Map.Entry<String, List<GraphNode>> entry : entityNodesByProcess.entrySet()) {
    String processGuid = entry.getKey();  // "PROC_12345"
    List<GraphNode> entityNodes = entry.getValue();  // [节点1, 节点2, 节点3]
    
    // 处理流程...
}
```

---

### 步骤2.1：按实体类型分组

**函数：`groupByEntityType(nodes)`**

```java
Map<String, List<GraphNode>> result = new HashMap<>();

for (GraphNode node : nodes) {
    String type = extractEntityType(node);  // 从 nodeId 提取
    result.computeIfAbsent(type, k -> new ArrayList<>())
          .add(node);
}
```

#### 如何提取实体类型？

**函数：`extractEntityType(node)`**

```java
String nodeId = node.getNodeId();

if (nodeId.contains("_FILE_")) return "file";
if (nodeId.contains("_DOMAIN_")) return "domain";
if (nodeId.contains("_NETWORK_")) return "network";
if (nodeId.contains("_REGISTRY_")) return "registry";

return "unknown";
```

**示例：**
- `PROC_12345_FILE_hash1` → `"file"`
- `PROC_12345_DOMAIN_hash2` → `"domain"`
- `PROC_12345_NETWORK_hash3` → `"network"`

#### 输出结果

```java
byType = {
    "file" -> [实体节点1, 实体节点2, 实体节点3]
}
```

---

### 步骤2.2：去重

**函数：`deduplicateNodes(nodes, entityType)`**

```java
Map<String, GraphNode> uniqueMap = new LinkedHashMap<>();

for (GraphNode node : nodes) {
    // ✅ 直接使用 nodeId 作为唯一键
    // nodeId 已经包含了唯一性信息（如 PROC_12345_FILE_hash123）
    String nodeId = node.getNodeId();
    
    if (!uniqueMap.containsKey(nodeId)) {
        uniqueMap.put(nodeId, node);
    } else {
        // ⚠️ 理论上不应该走到这里，因为 EntityExtractor 已经去重了
        log.warn("【实体去重】发现重复的实体节点: nodeId={}", nodeId);
    }
}

return new ArrayList<>(uniqueMap.values());
```

#### 去重规则：直接使用 nodeId

**重要优化：** 
- 实体节点的 `nodeId` 在 `EntityExtractor` 创建时已经基于唯一字段生成
- `nodeId` 格式：`processGuid_TYPE_hash(uniqueFields)`
- 因此不需要重新计算唯一键，直接使用 `nodeId` 即可

#### nodeId 生成规则（在 EntityExtractor 中）

| 实体类型 | nodeId 格式 | 唯一字段 |
|---------|-----------|---------|
| **file** | `processGuid_FILE_hash(fileMd5+"_"+filename)` | `fileMd5 + targetFilename` |
| **domain** | `processGuid_DOMAIN_hash(requestDomain)` | `requestDomain` |
| **network** | `processGuid_NETWORK_hash(destAddress)` | `destAddress` |
| **registry** | `processGuid_REGISTRY_hash(targetObject)` | `targetObject` |

**示例：**
```java
节点1: PROC_12345_FILE_abc123def456    // hash(fileMd5 + filename)
节点2: PROC_12345_DOMAIN_789abc012    // hash(requestDomain)
节点3: PROC_12345_NETWORK_345def678   // hash(destAddress)
```

#### EntityExtractor 中的去重

在 `EntityExtractor.extractEntitiesFromGraph` 中，**已经进行了去重**：

```java
// 检查节点是否已存在（去重）
if (graph.hasNode(entityNodeId)) {
    // 节点已存在，合并日志/告警到同一个节点
    existingNode.addLog(entityLog);  // 或 addAlarm(alarm)
    continue;  // 不创建新节点
}

// 创建新的实体节点
GraphNode entityNode = createEntityNode(entityNodeId, entityType, entityLog);
entityNodesToAdd.add(entityNode);
```

**关键点：**
- 相同的 `entityNodeId` → 合并到同一个节点
- 不会创建重复的节点

#### 为什么 deduplicateNodes 还需要去重？

虽然 `EntityExtractor` 已经去重了，`deduplicateNodes` 仍然保留作为**兜底保护**：

1. **防御性编程**：万一有遗漏的边界情况
2. **代码清晰性**：明确表达"去重"这个语义
3. **未来扩展性**：如果有其他路径添加实体节点

**实际情况：** 理论上，`deduplicateNodes` 不应该发现任何重复节点。如果发现了，会打印警告日志。

#### 示例结果

假设3个节点：

```java
节点1: PROC_12345_FILE_hash1 (malware.exe)
节点2: PROC_12345_FILE_hash2 (config.txt)
节点3: PROC_12345_FILE_hash3 (data.log)

// 去重后（nodeId 都不同，全部保留）
uniqueNodes = [节点1, 节点2, 节点3]
```

---

### 步骤2.3：应用过滤规则

**函数：`applyFilterRules(entityType, nodes)`**

根据实体类型调用不同的过滤函数：

```java
switch (entityType.toLowerCase()) {
    case "file":
        return filterFileNodes(nodes, 3);      // 保留3个
        
    case "domain":
        return filterDomainNodes(nodes, 5);    // 保留5个
        
    case "network":
        return filterNetworkNodes(nodes, 5);   // 保留5个
        
    case "registry":
        return filterRegistryNodes(nodes, 3);  // 保留3个
        
    default:
        return nodes;
}
```

---

## 文件节点过滤详解

**函数：`filterFileNodes(nodes, limit=3)`**

### 过滤规则

文件节点的过滤最复杂，分为两类：

1. **优先文件（Priority Files）**
   - 条件：**优先后缀** + **opType=create**
   - 处理：**全部保留**（不受数量限制）
   
2. **普通文件（Normal Files）**
   - 条件：不满足优先文件条件的所有文件
   - 处理：**保留最早的 3 个**

### 优先文件后缀列表

```java
PRIORITY_FILE_EXTENSIONS = {
    ".exe",   // 可执行文件
    ".dll",   // 动态链接库
    ".bat",   // 批处理文件
    ".ps1",   // PowerShell 脚本
    ".vbs",   // VBScript 脚本
    ".msi",   // 安装包
    ".jsp",   // Java Server Pages
    ".php",   // PHP 脚本
    ".asp",   // ASP 脚本
    ".sh",    // Shell 脚本
    ".so"     // 共享库
}
```

**选择依据：** 这些后缀的文件通常与恶意行为相关，具有高安全价值

---

### 具体流程

#### 第1步：分类优先文件 vs 普通文件

```java
List<GraphNode> priorityFiles = new ArrayList<>();
List<GraphNode> normalFiles = new ArrayList<>();

for (GraphNode node : nodes) {
    String filename = extractFilename(node);   // 从日志中获取文件名
    String opType = extractOpType(node);       // 从日志中获取操作类型
    
    // 判断：优先后缀 + opType=create → 优先文件
    if (hasPriorityExtension(filename) && "create".equalsIgnoreCase(opType)) {
        priorityFiles.add(node);
    } else {
        normalFiles.add(node);
    }
}
```

**对于我们的示例：**

| 节点 | 文件名 | opType | 优先后缀？ | 分类 |
|-----|--------|--------|-----------|------|
| 节点1 | `malware.exe` | `create` | ✅ `.exe` | **优先文件** |
| 节点2 | `config.txt` | `create` | ❌ `.txt` | 普通文件 |
| 节点3 | `data.log` | `modify` | ❌ `.log` | 普通文件 |

```java
priorityFiles = [节点1]           // malware.exe
normalFiles = [节点2, 节点3]      // config.txt, data.log
```

---

#### 第2步：优先文件全部保留

```java
List<GraphNode> result = new ArrayList<>(priorityFiles);
// result = [节点1]
```

**关键点：** 优先文件不受数量限制（`limit=3`），全部保留！

---

#### 第3步：普通文件保留最早的 N 个

```java
if (!normalFiles.isEmpty()) {
    // 按时间升序排序（最早的在前）
    normalFiles.sort((a, b) -> compareByTime(a, b, true));
    
    // 取前 limit 个
    int count = Math.min(limit, normalFiles.size());
    result.addAll(normalFiles.subList(0, count));
}
```

**排序依据：** `startTime` 字段

提取逻辑：
1. **优先从日志中提取** `RawLog.startTime`
2. **如果没有日志，从告警中提取** `RawAlarm.startTime`

```java
normalFiles.sort((a, b) -> compareByTime(a, b, true));
// true 表示升序：早的在前，新的在后

// 排序后：
// [节点2 (config.txt, 10:01:00), 节点3 (data.log, 10:02:00)]
```

**说明：**
- `startTime` 表示事件的开始时间（日志记录时间或告警触发时间）
- 时间格式通常为 ISO 8601 字符串（如 `2023-10-01T10:01:00Z`）
- 按字符串字典序比较，早的时间在前

**取前3个：**
```java
int count = Math.min(3, 2);  // min(limit=3, normalFiles.size()=2) = 2
result.addAll(normalFiles.subList(0, 2));
// 添加: [节点2, 节点3]
```

---

#### 最终结果

```java
filtered = [
    节点1 (malware.exe, 优先文件),
    节点2 (config.txt, 普通文件-最早),
    节点3 (data.log, 普通文件-第2早)
]
```

**保留节点：** 所有3个节点都保留
**移除节点：** 无

---

### 更复杂的场景示例

假设有 **10 个文件节点**：

```
优先文件（后缀+create）:
  1. malware.exe      (10:00, create)
  2. trojan.dll       (10:05, create)
  3. payload.bat      (10:10, create)
  4. script.ps1       (10:15, create)

普通文件:
  5. config.txt       (10:01, create)
  6. data.log         (10:02, modify)
  7. readme.md        (10:03, create)
  8. settings.ini     (10:04, modify)
  9. temp.tmp         (10:06, create)
 10. output.dat       (10:20, create)
```

**过滤后保留：**

```
优先文件（全部保留）:
  1. malware.exe
  2. trojan.dll
  3. payload.bat
  4. script.ps1

普通文件（最早的3个）:
  5. config.txt       (10:01, 最早)
  6. data.log         (10:02, 第2早)
  7. readme.md        (10:03, 第3早)

✅ 总共保留: 7 个节点
❌ 移除: settings.ini, temp.tmp, output.dat
```

**关键点：**
- 4个优先文件全部保留（不受 limit=3 限制）
- 6个普通文件中保留最早的3个

---

## 其他实体类型的过滤规则

### Domain（域名）节点过滤

**函数：`filterDomainNodes(nodes, limit=5)`**

```java
// 规则：保留最早的5个
if (nodes.size() <= 5) {
    return nodes;  // 不超过限制，全部保留
}

// 按时间升序排序（最早的在前）
nodes.sort((a, b) -> compareByTime(a, b, true));

// 取前5个
return nodes.stream().limit(5).collect(Collectors.toList());
```

**示例：**
```
原始: 8个域名节点
排序: 按 startTime 升序
保留: 最早的5个
移除: 最新的3个
```

---

### Network（网络连接）节点过滤

**函数：`filterNetworkNodes(nodes, limit=5)`**

```java
// 规则：保留最早的5个（与 domain 相同）
if (nodes.size() <= 5) {
    return nodes;
}

nodes.sort((a, b) -> compareByTime(a, b, true));
return nodes.stream().limit(5).collect(Collectors.toList());
```

---

### Registry（注册表）节点过滤

**函数：`filterRegistryNodes(nodes, limit=3)`**

```java
// 规则：保留最早的3个
if (nodes.size() <= 3) {
    return nodes;
}

// 按时间升序排序（最早的在前）
nodes.sort((a, b) -> compareByTime(a, b, true));
return nodes.stream().limit(3).collect(Collectors.toList());
```

---

## 过滤规则总结表

| 实体类型 | 数量限制 | 优先级规则 | 排序字段 | 排序方式 |
|---------|---------|-----------|---------|---------|
| **file** | 3个（普通） | 优先后缀+create **全部保留** | `startTime` | 升序（早→晚） |
| **domain** | 5个 | 无特殊优先级 | `startTime` | 升序（早→晚） |
| **network** | 5个 | 无特殊优先级 | `startTime` | 升序（早→晚） |
| **registry** | 3个 | 无特殊优先级 | `startTime` | 升序（早→晚） |

**排序说明：**
- **升序（早→晚）**：时间最早的节点排在前面，保留前 N 个，即保留最早发生的事件
- **`startTime` 提取优先级**：优先从日志中提取，如果没有日志则从告警中提取
- **时间格式**：通常为 ISO 8601 字符串（如 `2023-10-01T10:00:00Z`），按字典序比较

---

## 步骤2.4：标记要移除的节点

```java
// 标记要移除的节点
for (GraphNode node : uniqueNodes) {
    if (!filtered.contains(node)) {
        nodesToRemove.add(node.getNodeId());
    }
}
```

**逻辑：**
- `uniqueNodes` - 去重后的节点列表
- `filtered` - 应用过滤规则后保留的节点列表
- `nodesToRemove` - 需要移除的节点ID集合

**对于我们的示例：**
```java
uniqueNodes = [节点1, 节点2, 节点3]
filtered = [节点1, 节点2, 节点3]
nodesToRemove = []  // 所有节点都保留，无需移除
```

---

## 步骤3：批量移除节点

```java
// 从图中移除标记的节点
for (String nodeId : nodesToRemove) {
    graph.removeNode(nodeId);
}

log.info("【实体过滤】过滤完成，移除 {} 个实体节点，剩余节点数={}", 
        nodesToRemove.size(), graph.getNodeCount());
```

**注意：** `removeNode` 会同时移除节点及其关联的所有边

---

## 完整流程图

```
filterEntityNodesInGraph(graph)
    │
    ├─【步骤1】收集实体节点，按 processGuid 分组
    │   └─ groupEntityNodesByProcess(graph)
    │       │
    │       ├─ 遍历所有节点 (graph.getAllNodes())
    │       │
    │       ├─ 判断是否是实体节点 (isEntityNode)
    │       │   └─ 检查 nodeType: file/domain/network/registry
    │       │
    │       ├─ 找到父进程 (findProcessGuidForEntityNode)
    │       │   ├─ 方式1: graph.getParents(nodeId)
    │       │   └─ 方式2: 从 nodeId 提取 (兜底)
    │       │
    │       └─ 按 processGuid 分组
    │           Result: {"PROC_12345" -> [节点1, 节点2, 节点3]}
    │
    ├─【步骤2】对每个 processGuid 的实体节点进行过滤
    │   └─ for (processGuid, entityNodes)
    │       │
    │       ├─【2.1】按实体类型分组
    │       │   └─ groupByEntityType(nodes)
    │       │       └─ 根据 nodeId 中的标识符分类
    │       │           Result: {"file" -> [节点1, 节点2, 节点3]}
    │       │
    │       ├─【2.2】对每种类型处理
    │       │   └─ for (entityType, nodesOfType)
    │       │       │
    │       │       ├─ 去重 (deduplicateNodes)
    │       │       │   ├─ 直接使用 nodeId 作为唯一键
    │       │       │   │   （nodeId 在创建时已基于唯一字段生成）
    │       │       │   │
    │       │       │   └─ 理论上不应有重复（EntityExtractor 已去重）
    │       │       │       Result: [节点1, 节点2, 节点3]
    │       │       │
    │       │       ├─ 应用过滤规则 (applyFilterRules)
    │       │       │   │
    │       │       │   └─ filterFileNodes(nodes, 3)
    │       │       │       │
    │       │       │       ├─ 分类: 优先文件 vs 普通文件
    │       │       │       │   ├─ 优先文件: 后缀在列表 + opType=create
    │       │       │       │   │   [节点1: malware.exe]
    │       │       │       │   │
    │       │       │       │   └─ 普通文件: 其他所有文件
    │       │       │       │       [节点2: config.txt, 节点3: data.log]
    │       │       │       │
    │       │       │       ├─ 优先文件全部保留
    │       │       │       │   Result: [节点1]
    │       │       │       │
    │       │       │       └─ 普通文件保留最早的3个
    │       │       │           ├─ 按时间升序排序
    │       │       │           │   [节点2(10:01), 节点3(10:02)]
    │       │       │           │
    │       │       │           └─ 取前3个
    │       │       │               Result: [节点2, 节点3]
    │       │       │
    │       │       │       最终 Result: [节点1, 节点2, 节点3]
    │       │       │
    │       │       └─ 标记要移除的节点
    │       │           └─ nodesToRemove = uniqueNodes - filtered
    │       │               Result: [] (所有节点都保留)
    │       │
    │       └─ log: processGuid, type, 原数量, 去重后, 过滤后
    │
    └─【步骤3】批量移除节点
        └─ for (nodeId in nodesToRemove)
            └─ graph.removeNode(nodeId)
```

---

## 字段提取优先级说明

在过滤过程中，需要从实体节点中提取一些字段（如文件名、操作类型、时间）用于判断和排序。由于实体节点可能同时包含**日志**（`logs`）和**告警**（`alarms`），需要明确字段的提取优先级。

### 提取规则

**统一优先级：日志优先于告警**

```
如果节点有日志（logs）：
  ├─ 优先从 logs[0] 中提取字段
  └─ 如果字段为空，再从 alarms[0] 中提取

如果节点没有日志：
  └─ 从 alarms[0] 中提取字段
```

### 具体字段的提取逻辑

#### 1. 文件名（`extractFilename`）

```java
// 优先级：
1. log.getTargetFilename()  // 日志中的目标文件名
2. log.getFileName()         // 日志中的文件名
3. alarm.getTargetFilename() // 告警中的目标文件名
4. alarm.getFileName()       // 告警中的文件名
```

#### 2. 操作类型（`extractOpType`）

```java
// 优先级：
1. log.getOpType()    // 日志中的操作类型（create/modify/delete等）
2. alarm.getOpType()  // 告警中的操作类型
```

#### 3. 开始时间（`extractStartTime`）

```java
// 优先级：
1. log.getStartTime()    // 日志的开始时间
2. alarm.getStartTime()  // 告警的开始时间
```

**重要：** `startTime` 是排序的关键字段，决定了"最早的"实体节点

### 为什么日志优先于告警？

1. **数据完整性**：日志通常包含更完整的操作信息（如文件路径、操作类型）
2. **时间准确性**：日志记录的时间通常更接近实际事件发生时间
3. **语义一致性**：实体节点本质上是从日志中提取的，告警只是补充数据

### 示例场景

**场景1：节点同时有日志和告警**
```java
实体节点: PROC_12345_FILE_hash1
  ├── logs[0]: {
  │      targetFilename: "malware.exe",
  │      opType: "create",
  │      startTime: "2023-10-01T10:00:00Z"
  │   }
  └── alarms[0]: {
         targetFilename: "malware.exe",
         opType: "execute",
         startTime: "2023-10-01T10:00:05Z"  // 告警时间稍晚
      }

提取结果：
  ├─ filename: "malware.exe"        (从 log)
  ├─ opType: "create"               (从 log)
  └─ startTime: "2023-10-01T10:00:00Z"  (从 log, 更早)
```

**场景2：节点只有告警没有日志**
```java
实体节点: PROC_12345_FILE_hash2
  ├── logs: []  // 空
  └── alarms[0]: {
         targetFilename: "config.txt",
         opType: "modify",
         startTime: "2023-10-01T10:01:00Z"
      }

提取结果：
  ├─ filename: "config.txt"        (从 alarm)
  ├─ opType: "modify"              (从 alarm)
  └─ startTime: "2023-10-01T10:01:00Z"  (从 alarm)
```

---

## 关键设计点

### 1. 为什么按 processGuid 分组？

**原因：** 确保每个进程的实体节点**独立过滤**，互不影响

```
场景：
  进程A (chrome.exe) 产生 10 个 file 节点
  进程B (malware.exe) 产生 3 个 file 节点

不分组过滤:
  可能导致进程B的3个文件被进程A的10个文件"挤掉"
  
按 processGuid 分组:
  进程A: 保留 3+N 个（优先文件+普通文件前3）
  进程B: 保留 3+M 个（优先文件+普通文件前3）
  两者独立计算，不会相互影响
```

---

### 2. 为什么文件有"优先文件"特殊处理？

**原因：** 安全分析中，某些文件类型具有更高的威胁价值

```
恶意行为常见模式：
  1. 下载/创建可执行文件 (.exe, .dll)
  2. 创建脚本文件 (.bat, .ps1, .vbs)
  3. 植入 Web Shell (.jsp, .php, .asp)

这些文件的 create 操作通常是攻击链的关键环节，必须全部保留！
```

**示例场景：**
```
攻击者行为:
  1. 创建 dropper.exe (create)     ← 优先文件，必须保留
  2. 创建 payload.dll (create)     ← 优先文件，必须保留
  3. 创建 launcher.bat (create)    ← 优先文件，必须保留
  4. 创建 100 个 log 文件 (create) ← 普通文件，只保留前3个

如果不区分优先级，可能导致关键的恶意文件被过滤掉！
```

---

### 3. 为什么普通文件保留"最早的"而不是"最新的"？

**原因：** 攻击链分析中，早期的文件操作通常更接近攻击起点

```
攻击时间线:
  10:00 - 创建 initial_payload.exe     ← 攻击入口点（最重要）
  10:05 - 创建 config.txt              ← 配置文件
  10:10 - 创建 persistence.bat         ← 持久化脚本
  10:15 - 修改 1000 个临时文件         ← 噪音数据

保留最早的3个 → 更可能捕获攻击的关键初始阶段
```

---

### 4. 日志与告警的合并机制

在 `EntityExtractor` 中，日志和告警会**合并到同一个实体节点**：

```java
// 检查节点是否已存在（去重）
if (graph.hasNode(entityNodeId)) {
    // 节点已存在，合并日志或告警
    existingNode.addLog(entityLog);   // 添加日志
    existingNode.addAlarm(alarm);     // 添加告警
    continue;
}
```

**机制说明：**
- 相同的文件操作（相同 MD5 + 文件名）→ 生成相同的 `entityNodeId`
- 日志和告警会被添加到**同一个节点**的日志列表和告警列表中
- 不存在"日志节点"和"告警节点"的区分，只有一个包含所有相关数据的实体节点

**示例：**
```
实体节点: PROC_12345_FILE_hash1 (malware.exe)
  ├── logs: [log1, log2]          // 文件创建日志、文件修改日志
  └── alarms: [alarm1, alarm2]    // 恶意文件告警、文件执行告警
  
这是同一个节点，包含了所有相关的日志和告警信息
```

---

## 延迟拆分架构下的优势

### 传统架构的问题

```
传统流程:
  1. 建图时就创建所有实体节点
  2. 进程链裁剪时，实体节点的父进程可能被裁剪掉
  3. 导致实体节点断链（孤立节点）
  4. 需要额外的逻辑处理断链的实体节点
```

### 延迟拆分的优势

```
延迟拆分流程:
  1. 建图时只创建进程节点
  2. 进程链裁剪（只基于进程关系）
  3. 从保留的进程节点中提取实体节点
  4. 应用实体过滤规则
  
优势:
  ✅ 实体节点的父进程一定存在（因为是从保留的进程节点提取的）
  ✅ 不会出现断链的实体节点
  ✅ 建图性能更好（初期节点数更少）
  ✅ 裁剪更精准（只基于进程关系，不受实体节点干扰）
```

### 代码体现

```java
// findProcessGuidForEntityNode 主要依赖边关系
List<String> parents = graph.getParents(entityNode.getNodeId());
if (!parents.isEmpty()) {
    return parents.get(0);  // ✅ 在延迟拆分架构下，父节点一定存在
}
```

在延迟拆分架构下，`getParents` 总能找到父进程节点，因为：
1. 实体节点是在进程链裁剪后才创建的
2. 只从图中**已存在**的进程节点提取实体
3. 创建实体节点时就建立了边关系：`graph.addEdge(processGuid, entityNodeId, "连接")`

---

## 调用时机

`filterEntityNodesInGraph` 在进程链构建流程中的位置：

```
ProcessChainBuilder.buildIncidentChain
    │
    ├─ 1. 构建完整图 (ProcessChainGraphBuilder.buildGraph)
    │   └─ 只包含进程节点，不含实体节点
    │
    ├─ 2. 全树遍历 (fullTreeTraversal)
    │   └─ 从起点节点向上、向下遍历，收集相关节点
    │
    ├─ 3. 子图提取 (extractSubgraph)
    │   └─ 创建包含相关节点的子图（裁剪）
    │
    ├─ 4. 创建虚拟父节点 (createVirtualParentsForSubgraph)
    │   └─ 为断链节点创建虚拟父节点
    │
    ├─ 5. 图分析 (identifyRootNodes, detectCycles)
    │   └─ 识别根节点、检测环
    │
    ├─ 6. 调整虚拟父节点链接 (adjustVirtualParentLinks)
    │   └─ 将断链节点连接到根节点
    │
    ├─ 7. 实体提取 (EntityExtractor.extractEntitiesFromGraph) ← 这里创建实体节点
    │   └─ 从保留的进程节点中提取实体节点
    │
    ├─ 8. 实体过滤 (EntityFilterUtil.filterEntityNodesInGraph) ← 🎯 这里调用
    │   └─ 对实体节点进行去重、优先级排序、数量控制
    │
    └─ 9. 断链节点标记 (addExploreNodesForBrokenChains)
        └─ 为断链子树添加 EXPLORE 节点
```

**关键点：**
- 实体过滤发生在**实体提取之后**
- 此时图中已有实体节点和边关系
- 过滤不会影响进程链结构（只移除部分实体节点）

---

## 日志输出示例

```
【实体过滤】开始过滤，当前节点数=25

【实体过滤】processGuid=PROC_12345, type=file, 原数量=10, 去重后=8, 过滤后=7
【文件过滤】优先文件(后缀+create)数=4, 普通文件数=4
【文件过滤】普通文件保留最早的3个
【文件过滤】最终保留文件数=7 (优先4个 + 普通3个)

【实体过滤】processGuid=PROC_67890, type=domain, 原数量=8, 去重后=6, 过滤后=5

【实体过滤】过滤完成，移除 6 个实体节点，剩余节点数=19
```

---

## 扩展阅读

- **[代码阅读指南-完整流程详解.md](./代码阅读指南-完整流程详解.md)** - 进程链构建的总体流程
- **[实体提取详解.md](./实体提取详解.md)** - 实体节点的创建过程（如果有）
- **[延迟拆分优化说明.md](./延迟拆分优化-实施步骤清单.md)** - 延迟拆分架构的设计思想

---

## 总结

`filterEntityNodesInGraph` 是实体节点过滤的核心，通过以下机制确保进程链图的质量：

1. **按 processGuid 分组** - 每个进程的实体节点独立过滤
2. **按实体类型分组** - 不同类型应用不同规则
3. **去重机制** - 直接使用 nodeId（在创建时已保证唯一性）
4. **优先级机制** - 优先文件（特定后缀+create）全部保留
5. **数量控制** - 避免图过于庞大，保留最关键的信息

在延迟拆分架构下，实体过滤更加可靠，因为实体节点的父进程节点一定存在，不会出现断链问题。



